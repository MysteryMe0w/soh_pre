import os
import sys
import numpy as np
import tensorflow as tf
import json
import time
from datetime import datetime
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Dense,
    Conv1D,
    Bidirectional,
    LSTM,
    Dropout,
    Input,
    MultiHeadAttention,
    LayerNormalization,
)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# å¯¼å…¥æ”¹è¿›çš„PSOä¼˜åŒ–å™¨
from pso_optimizer_improved_v1 import ImprovedPSOOptimizerV1, FastPSOOptimizer

# å¯¼å…¥åŸå§‹train.pyä¸­çš„æ•°æ®
from train import X_normalized, y_normalized, battery_label, test_label

import warnings

warnings.filterwarnings("ignore")


def set_seed(seed=42):
    """è®¾ç½®éšæœºç§å­"""
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)


def create_optimized_model(input_shape, params):
    """æ ¹æ®PSOä¼˜åŒ–åçš„å‚æ•°åˆ›å»ºæ¨¡å‹"""
    inputs = Input(shape=input_shape)

    # Transformer Encoder
    x = Dense(params["embed_dim"])(inputs)

    attention_output = MultiHeadAttention(
        num_heads=params["num_heads"],
        key_dim=params["embed_dim"] // params["num_heads"],
    )(x, x)
    attention_output = Dropout(params["transformer_dropout"])(attention_output)
    out1 = LayerNormalization(epsilon=1e-6)(attention_output + x)

    ffn_output = Dense(params["ff_dim"], activation="relu")(out1)
    ffn_output = Dense(params["embed_dim"])(ffn_output)
    ffn_output = Dropout(params["transformer_dropout"])(ffn_output)
    x = LayerNormalization(epsilon=1e-6)(ffn_output + out1)

    # CNN Layer
    x = Conv1D(
        filters=params["cnn_filters"],
        kernel_size=params["cnn_kernel_size"],
        padding="same",
        activation="relu",
    )(x)

    # BiLSTM Layer
    x = Bidirectional(LSTM(params["lstm_units"], return_sequences=False))(x)
    x = Dropout(params["final_dropout"])(x)

    # Output Layer
    outputs = Dense(1, activation="sigmoid")(x)

    model = Model(inputs=inputs, outputs=outputs)
    return model


def run_pso_optimization(run_id=1, seed=42, fast_mode=False):
    """è¿è¡ŒPSOè¶…å‚æ•°ä¼˜åŒ–"""

    set_seed(seed)

    print("\n" + "=" * 80)
    print(f"ğŸš€ PSO ä¼˜åŒ– - Run #{run_id} (Seed: {seed})")
    if fast_mode:
        print("   æ¨¡å¼: å¿«é€Ÿæ¨¡å¼ (é¢„è®¡ 30-60åˆ†é’Ÿ)")
    else:
        print("   æ¨¡å¼: æ ‡å‡†æ¨¡å¼ (é¢„è®¡ 1.5-2å°æ—¶)")
    print("=" * 80)

    # å‡†å¤‡æ•°æ®
    X_train = X_normalized[battery_label != test_label]
    y_train = y_normalized[battery_label != test_label]
    X_test = X_normalized[battery_label == test_label]
    y_test = y_normalized[battery_label == test_label]

    # ä»è®­ç»ƒé›†ä¸­åˆ’åˆ†éªŒè¯é›†
    X_t, X_val, y_t, y_val = train_test_split(
        X_train,
        y_train,
        test_size=0.15,  # 0.2 â†’ 0.15ï¼ˆå‡å°‘éªŒè¯é›†å¤§å°åŠ é€Ÿï¼‰
        random_state=seed,
    )

    print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†:")
    print(f"   è®­ç»ƒé›†: {X_t.shape}")
    print(f"   éªŒè¯é›†: {X_val.shape}")
    print(f"   æµ‹è¯•é›†: {X_test.shape}")

    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = os.path.join(
        os.path.dirname(os.path.abspath(__file__)), f"models/pso_optimized/run_{run_id}"
    )
    os.makedirs(save_dir, exist_ok=True)

    # åˆ›å»ºPSOä¼˜åŒ–å™¨
    start_time = time.time()

    if fast_mode:
        print("\nâš¡ ä½¿ç”¨å¿«é€ŸPSOé…ç½®...")
        optimizer = FastPSOOptimizer(X_t, y_t, X_val, y_val, save_dir=save_dir)
    else:
        print("\nğŸ¯ ä½¿ç”¨æ ‡å‡†PSOé…ç½®...")
        optimizer = ImprovedPSOOptimizerV1(
            X_t,
            y_t,
            X_val,
            y_val,
            n_particles=12,
            max_iter=20,
            train_epochs=50,
            patience=8,
            save_dir=save_dir,
            use_multi_gpu=True,
        )

    # æ‰§è¡Œä¼˜åŒ–
    print("\n" + "=" * 80)
    print("å¼€å§‹PSOä¼˜åŒ–...")
    print("=" * 80)

    best_params, best_mse_val, best_metrics = optimizer.optimize()

    pso_time = time.time() - start_time
    print(f"\nâ±ï¸  PSOä¼˜åŒ–å®Œæˆï¼Œè€—æ—¶: {pso_time/60:.2f} åˆ†é’Ÿ")

    # ç»˜åˆ¶æ”¶æ•›æ›²çº¿
    optimizer.plot_convergence(os.path.join(save_dir, "convergence.png"))

    # ç”¨æœ€ä¼˜å‚æ•°åœ¨å®Œæ•´è®­ç»ƒé›†ä¸Šé‡æ–°è®­ç»ƒ
    print("\n" + "=" * 80)
    print("ğŸ“ˆ ä½¿ç”¨æœ€ä¼˜å‚æ•°åœ¨å®Œæ•´è®­ç»ƒé›†ä¸Šè®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
    print("=" * 80)

    input_shape = (X_train.shape[1], X_train.shape[2])
    final_model = create_optimized_model(input_shape, best_params)

    final_model.compile(
        optimizer=Adam(learning_rate=best_params["learning_rate"]),
        loss="mse",
        metrics=["mae"],
    )

    callbacks = [
        EarlyStopping(
            monitor="loss", patience=30, restore_best_weights=True, verbose=1
        ),
        ReduceLROnPlateau(
            monitor="loss", factor=0.5, patience=10, min_lr=1e-8, verbose=1
        ),
    ]

    final_train_start = time.time()
    history = final_model.fit(
        X_train, y_train, epochs=200, batch_size=64, callbacks=callbacks, verbose=1
    )
    final_train_time = time.time() - final_train_start

    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
    print("\n" + "=" * 80)
    print("ğŸ“Š åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°...")
    print("=" * 80)

    y_pred_test = final_model.predict(X_test, verbose=0)

    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

    test_mse = mean_squared_error(y_test, y_pred_test)
    test_mae = mean_absolute_error(y_test, y_pred_test)
    test_rmse = np.sqrt(test_mse)
    test_r2 = r2_score(y_test, y_pred_test)

    # ä¿å­˜æ¨¡å‹
    model_path = os.path.join(save_dir, "optimized_model.h5")
    final_model.save(model_path)

    # ä¿å­˜é¢„æµ‹ç»“æœ
    np.save(os.path.join(save_dir, "y_test.npy"), y_test)
    np.save(os.path.join(save_dir, "y_pred.npy"), y_pred_test)

    # ä¿å­˜å®Œæ•´æŒ‡æ ‡
    results = {
        "run_id": run_id,
        "seed": seed,
        "fast_mode": fast_mode,
        "best_params": best_params,
        "pso_optimization_time_minutes": pso_time / 60,
        "final_training_time_seconds": final_train_time,
        "total_time_minutes": (pso_time + final_train_time) / 60,
        "validation_metrics": {
            "mse": float(best_mse_val),
            "mae": float(best_metrics["mae"]),
            "rmse": float(best_metrics["rmse"]),
            "r2": float(best_metrics["r2"]),
        },
        "test_metrics": {
            "mse": float(test_mse),
            "mae": float(test_mae),
            "rmse": float(test_rmse),
            "r2": float(test_r2),
        },
        "epochs_trained": len(history.history["loss"]),
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }

    with open(os.path.join(save_dir, "pso_metrics.json"), "w") as f:
        json.dump(results, f, indent=2)

    # æ‰“å°æœ€ç»ˆç»“æœ
    print("\n" + "=" * 80)
    print("âœ… PSOä¼˜åŒ–æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    print("=" * 80)
    print(f"\nğŸ“ˆ æµ‹è¯•é›†æ€§èƒ½:")
    print(f"   MSE:  {test_mse:.6f}")
    print(f"   MAE:  {test_mae:.6f}")
    print(f"   RMSE: {test_rmse:.6f}")
    print(f"   RÂ²:   {test_r2:.4f}")
    print(f"\nâ±ï¸  æ—¶é—´ç»Ÿè®¡:")
    print(f"   PSOä¼˜åŒ–: {pso_time/60:.2f} åˆ†é’Ÿ")
    print(f"   æœ€ç»ˆè®­ç»ƒ: {final_train_time:.2f} ç§’")
    print(f"   æ€»è€—æ—¶:   {(pso_time + final_train_time)/60:.2f} åˆ†é’Ÿ")
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {save_dir}")
    print("=" * 80 + "\n")

    return results


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="PSOè¶…å‚æ•°ä¼˜åŒ–è®­ç»ƒ")
    parser.add_argument("--run_id", type=int, default=1, help="è¿è¡Œç¼–å·")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    parser.add_argument("--fast", action="store_true", help="ä½¿ç”¨å¿«é€Ÿæ¨¡å¼")

    args = parser.parse_args()

    results = run_pso_optimization(
        run_id=args.run_id, seed=args.seed, fast_mode=args.fast
    )
